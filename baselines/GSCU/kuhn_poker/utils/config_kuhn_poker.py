# -*- coding:utf-8 -*-
from environment.kuhn_poker.policy_new import generate_policy_pool, test_policies, get_train_eval_pool
from argparse import Namespace

class Config:

    OBS_DIM = 13
    # NUM_ADV_POOL = 3
    NUM_ADV_POOL = 40
    ACTION_DIM = 2
    HIDDEN_DIM = 128
    LATENT_DIM = 2

    PURE_PO = [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]
    NE_PO = [[gamma/3,(1+gamma)/3,gamma] for gamma in [0,0.2,0.4,0.6,0.8,1]]
    # SAMPLE_P1 = [[0.25,0.67],[0.75,0.8],[0.67,0.4],[0.5,0.29],[0.28,0.10],[0.17,0.2],[1/3,1/3]]
    # SAMPLE_P1_SEEN = [[0.25,0.67],[0.75,0.8],[0.17,0.2]]
    # SAMPLE_P1_UNSEEN = [[0.67,0.4],[0.5,0.29],[0.28,0.10]]
    # SAMPLE_P1_MIX = [[0.25,0.67],[0.75,0.8],[0.67,0.4],[0.5,0.29],[0.28,0.10],[0.17,0.2]]

    # SAMPLE_P1_SEEN = [[0.7203244934421581, 0.417022004702574], [0.30233257263183977, 0.00011437481734488664], [0.0923385947687978, 0.14675589081711304], [0.34556072704304774, 0.1862602113776709], [0.538816734003357, 0.39676747423066994], [0.6852195003967595, 0.4191945144032948], [0.8781174363909454, 0.20445224973151743], [0.6704675101784022, 0.027387593197926163], [0.5586898284457517, 0.41730480236712697], [0.1981014890848788, 0.14038693859523377], [0.9682615757193975, 0.8007445686755367], [0.6923226156693141, 0.31342417815924284], [0.8946066635038473, 0.8763891522960383], [0.03905478323288236, 0.08504421136977791], [0.8781425034294131, 0.1698304195645689], [0.42110762500505217, 0.0983468338330501], [0.5331652849730171, 0.9578895301505019], [0.31551563100606295, 0.6918771139504734], [0.8346256718973729, 0.6865009276815837], [0.7501443149449675, 0.018288277344191806], [0.7481656543798394, 0.9888610889064947], [0.7892793284514885, 0.2804439920644052], [0.44789352617590517, 0.10322600657764203], [0.2936141483736795, 0.9085955030930956], [0.13002857211827767, 0.28777533858634874], [0.678835532939891, 0.019366957870297075], [0.2655466593722262, 0.21162811600005904], [0.053362545117080384, 0.4915731592803383], [0.14672857490581015, 0.5741176054920131], [0.6997583600209312, 0.5893055369032842], [0.4140559878195683, 0.10233442882782584], [0.41417926952690265, 0.6944001577277451], [0.5358964059155116, 0.04995345894608716], [0.5148891120583086, 0.6637946452197888], [0.5865550405019929, 0.9445947559908133], [0.13747470414623753, 0.9034019152878835], [0.8073912887095238, 0.13927634725075855], [0.16535419711693278, 0.3976768369855336], [0.34776585974550656, 0.9275085803960339], [0.7259979853504515, 0.7508121031361555]]
    # SAMPLE_P1_UNSEEN = [[0.25,0.67],[0.75,0.8],[0.67,0.4],[0.5,0.29],[0.28,0.10],[0.17,0.2],[1/3,1/3]]
    # SAMPLE_P1_MIX = SAMPLE_P1 = SAMPLE_P1_SEEN + SAMPLE_P1_UNSEEN

    # SAMPLE_P1_ALL = generate_policy_pool(56)
    # SAMPLE_P1_SEEN = SAMPLE_P1_ALL[:40]
    # SAMPLE_P1_EVAL = SAMPLE_P1_ALL[40:]
    args = Namespace(
        train_pool_size=40,
        rule_based_opponents=40,
        eval_pool_size=10
    )
    SAMPLE_P1_SEEN, SAMPLE_P1_EVAL = get_train_eval_pool(args)
    SAMPLE_P1_ALL = SAMPLE_P1_SEEN + SAMPLE_P1_EVAL
    SAMPLE_P1_UNSEEN = test_policies

    NE_P1 = [[1/3,1/3]]

    DATA_DIR = '../data/'
    VAE_MODEL_DIR = '../model_params/VAE/'
    VAE_RST_DIR = '../results/VAE/'

    RL_MODEL_DIR = '../model_params/RL/'
    RL_TRAINING_RST_DIR = '../results/RL/'

    ONLINE_TEST_RST_DIR = '../results/online_test/'

    OPPONENT_MODEL_DIR = '../model_params/opponent/'



